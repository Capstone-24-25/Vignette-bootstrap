---
title: "basic_bootstrap"
author: "Sumeng Xu"
date: "2024-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library and dataset

First we will load the necessary libraries, and the Obesity_sample data file.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(mosaic)
load("data/Obesity_sample.RData")
head(Obesity_sample)
```

### Explore the sample mean of weight in data set

```{r}
sample_weight <- ggplot(Obesity_sample) + 
  geom_histogram(aes(x = Weight), binwidth=5)
sample_weight
```

The histogram above displays the distribution of weights, with most data points concentrated between 40 and 100. It peaks around the 70-80 range, which is the most frequent weight in the data set.

To get a more precise data, we can use the following mean function to calculate the mean of sample weight.

```{r}
sample_weightm<-mean(~Weight, data=Obesity_sample) 
print(sample_weightm)
```

On average, the weight is around 85.94. However, since these samples are based on 700 observations, there is still variability when applying this result to the entire population in those countries.

### Bootstrapping

Now, let's practice doing **a single bootstrap**

The first line of code creates a bootstrap sample from the original data (Obesity_sample) using the resample function from the mosaic package. As mentioned earlier, a bootstrap sample is generated by randomly selecting observations with replacement, meaning some rows may appear multiple times while others may not appear at all. This simulates taking a new sample from the same population.

The second line of code calculates the mean weight from the bootstrap sample.

```{r}
set.seed(1970)
sample_weight_bootstrap = mosaic::resample(Obesity_sample)
mean(~Weight, data=sample_weight_bootstrap)
```

The result is around 87, slightly higher than the sample mean. This difference represents a bootstrap sampling error, which occurs because the bootstrap sample may not perfectly represent the original data. However, a single bootstrap iteration provides only one estimate, which is not enough to understand the overall variability of the bootstrap process. To get a more comprehensive view, we need to perform multiple bootstrap iterations.

Let’s proceed to conduct **1,000 bootstrap** samples to better capture the distribution and variability of the bootstrap means.

```{r}
# Generating 10,000 bootstrap samples from Obesity_sample
# Then calculates the mean for each bootstrap sample
set.seed(1970)

boot_weight = do(10000)*mean(~Weight, data=mosaic::resample(Obesity_sample))

ggplot(boot_weight) + 
  geom_histogram(aes(x=mean))
```

This histogram shows the distribution of the means from 10,000 bootstrap samples. The graph is approximately symmetric and bell-shaped, centered around the original sample mean, which was close to 86.

Comparing this to the graph of the original sample mean, the bootstrap distribution helps us understand the uncertainty in the sample mean as an estimate of the population mean. The narrow spread in the bootstrap distribution suggests that the sample mean is a fairly precise estimate, as most bootstrap means are clustered close to the original sample mean.

### Standard Errors

#### Bootstrap VS. the Origional Sample

First, let's calculate the origional sample's standard error:

```{r}
n <- nrow(Obesity_sample)
std_err_weight <- sd(~Weight, data = Obesity_sample) / sqrt(n)
std_err_weight
```

Then calculate the Bootstrap standard Error:

```{r}
boot_std_error <- boot_weight %>%
  summarize(std_err_weight = sd(mean)) 
boot_std_error
```

Although the two values are close (1.006 and 0.99), demonstrating consistency in the standard error estimate, there exists a difference of approximately 0.016, with the bootstrap standard error being slightly lower. This small discrepancy arises because the bootstrap method captures variability through resampling, which inherently smooths out extreme values by averaging across multiple simulated samples.

In contrast, the original sample standard error is derived solely from the observed dataset, assuming it is representative of the population and relying directly on the sample’s fixed variability. The lower bootstrap standard error suggests that the resampling approach estimates slightly less variability in the data compared to the original method, potentially reflecting a more refined measure of uncertainty.

## Action 1

```{r}
print(confint(boot_weight, level = 0.95))
```

Above is the 95% confidence interval for the average weight.

**True or false**: The histogram of the 1,000 Bootstrap, and the associated confidence interval, tell us that about 95% of all individuals weight between 84.04 and 87.86?

(answer: False: The histogram of the 1,000 Bootstrap and the associated confidence interval tell us that about 95% of the sample means (not individual weights) fall between 84.04 and 87.86. The confidence interval reflects the range within which we expect the true population mean to lie, based on the bootstrap sampling distribution of the mean, not the range of individual weights in the population.)

## Action 2

Now, try to do the same bootstrapping process for weight based on Gender

------------------------------------------------------------------------

(answer below )

```{r}
mean(Weight ~ Gender, data=Obesity_sample)

diffmean(Weight ~ Gender, data=Obesity_sample)
```

The difference in mean tells us that male weight 7.8 more than female.

```{r}
set.seed(1970)
# bootstrap 
boot_weight_gender = do(10000)*diffmean(Weight ~ Gender, data=mosaic::resample(Obesity_sample))
#visual 
ggplot(boot_weight_gender) + 
  geom_histogram(aes(x=diffmean))
# 95% confidence interval
confint(boot_weight_gender, level = 0.95)
```

The bootstrap analysis estimates a difference in means of approximately 5.81, with a 95% confidence interval ranging from 3.7 to 11.69. The bootstrap estimate of 5.81 is slightly lower than the original observed difference of 7.83. This discrepancy reflects the inherent variability captured by the bootstrap method, which averages across multiple resampled datasets.

Additionally, the original difference of 7.83 lies well within the 95% confidence interval [3.70, 11.69], indicating that the observed difference is consistent with what could be expected under random sampling variability.



Now, hope you already learned the basic of doing bootstrap! So far, we explored the concept and application of bootstrapping, a resampling method used to estimate the variability and confidence intervals of sample statistics. 





